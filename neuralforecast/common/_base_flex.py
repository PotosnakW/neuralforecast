
# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/common.base_windows.ipynb.

# %% auto 0
__all__ = ['BaseFlex']

# %% ../../nbs/common.base_windows.ipynb 5
import numpy as np
import torch
import torch.nn as nn
import pytorch_lightning as pl

from ._base_model import BaseModel
from ._scalers import TemporalNorm
from ..tsdataset import TimeSeriesDataModule
from ..utils import get_indexer_raise_missing

from ..common._instance_norm import RevIN
from ..common._tokenizers import Tokenizer

# %% ../../nbs/common.base_windows.ipynb 6
class BaseFlex(BaseModel):
    """Base Flex

    Base class for all windows-based models. The forecasts are produced separately
    for each window, which are randomly sampled during training.

    This class implements the basic functionality for all windows-based models, including:
    - PyTorch Lightning's methods training_step, validation_step, predict_step.<br>
    - fit and predict methods used by NeuralForecast.core class.<br>
    - sampling and wrangling methods to generate windows.
    """

    def __init__(
        self,
        h,
        input_token_len,
        output_token_len,
        stride,
        input_size,
        loss,
        valid_loss,
        learning_rate,
        max_steps,
        val_check_steps,
        batch_size,
        valid_batch_size,
        windows_batch_size,
        inference_windows_batch_size,
        start_padding_enabled,
        step_size=1,
        num_lr_decays=0,
        early_stop_patience_steps=-1,
        scaler_type="identity",
        futr_exog_list=None,
        hist_exog_list=None,
        stat_exog_list=None,
        exclude_insample_y=False,
        num_workers_loader=0,
        drop_last_loader=False,
        random_seed=1,
        alias=None,
        optimizer=None,
        optimizer_kwargs=None,
        lr_scheduler=None,
        lr_scheduler_kwargs=None,
        revin=True,
        revin_affine=False,
        revin_subtract_last=True,
        tokenizer_type='patch_fixed_length',
        lag=None, 
        padding_patch=None,
        ckpt_path=None,
        **trainer_kwargs,
    ):
        super().__init__(
            random_seed=random_seed,
            loss=loss,
            valid_loss=valid_loss,
            optimizer=optimizer,
            optimizer_kwargs=optimizer_kwargs,
            lr_scheduler=lr_scheduler,
            lr_scheduler_kwargs=lr_scheduler_kwargs,
            futr_exog_list=futr_exog_list,
            hist_exog_list=hist_exog_list,
            stat_exog_list=stat_exog_list,
            max_steps=max_steps,
            early_stop_patience_steps=early_stop_patience_steps,
            ckpt_path=ckpt_path,
            alias=alias,
            **trainer_kwargs,
        )

        if tokenizer_type=='patch_fixed_length':
            input_token_len = torch.minimum(
                                    torch.tensor(input_token_len), 
                                    torch.tensor(input_size + stride)
                                    )
        if tokenizer_type=='lags':
            input_size=input_size*lag
        
        self.input_token_len = input_token_len
        self.output_token_len = torch.minimum(
                                    torch.tensor(output_token_len), 
                                    torch.tensor(h)
                                    )
        
        self.c_out = self.loss.outputsize_multiplier

        self.h = h
        self.input_size = input_size
        self.windows_batch_size = windows_batch_size
        self.start_padding_enabled = start_padding_enabled
        if start_padding_enabled:
            self.padder_train = nn.ConstantPad1d(
                padding=(self.input_size - 1, self.h), value=0
            )
        else:
            #self.padder_train = nn.ConstantPad1d(padding=(0, self.h), value=0)
            self.padder_train = nn.ConstantPad1d(padding=(0, self.output_token_len), value=0)

        # Batch sizes
        self.batch_size = batch_size
        if valid_batch_size is None:
            self.valid_batch_size = batch_size
        else:
            self.valid_batch_size = valid_batch_size

        if inference_windows_batch_size is None: 
            self.inference_windows_batch_size = windows_batch_size
        else:
            self.inference_windows_batch_size = inference_windows_batch_size

        # Optimization
        self.learning_rate = learning_rate
        self.max_steps = max_steps
        self.num_lr_decays = num_lr_decays
        self.lr_decay_steps = (
            max(max_steps // self.num_lr_decays, 1) if self.num_lr_decays > 0 else 10e7
        )
        self.early_stop_patience_steps = early_stop_patience_steps
        self.val_check_steps = val_check_steps
        self.windows_batch_size = windows_batch_size
        self.step_size = step_size

        self.exclude_insample_y = exclude_insample_y

        # Scaler
        self.scaler = TemporalNorm(
            scaler_type=scaler_type,
            dim=1,  # Time dimension is 1.
            num_features=1 + len(self.hist_exog_list) + len(self.futr_exog_list),
        )

        # Fit arguments
        self.val_size = 0
        self.test_size = 0

        # Model state
        self.decompose_forecast = False

        # DataModule arguments
        self.num_workers_loader = num_workers_loader
        self.drop_last_loader = drop_last_loader
        # used by on_validation_epoch_end hook
        self.validation_step_outputs = []
        self.alias = alias
        
        token_num = int((input_size - input_token_len) / stride + 1)
        
        self.revin = revin
        if self.revin:
            self.revin_layer = RevIN(1, # univariate!!
                                     affine=revin_affine, 
                                     subtract_last=revin_subtract_last
                                    )
        self.tokenizer_type = tokenizer_type
        self.tokenizer = Tokenizer(tokenizer_type,
                                   token_len=input_token_len,
                                   stride=stride,
                                   token_num=token_num,
                                   lag=lag,
                                   padding_patch=padding_patch,
                                   )

    def _create_windows(self, batch, step, window_size, w_idxs=None):
        # Parse common data
        temporal_cols = batch["temporal_cols"]
        temporal = batch["temporal"]

        if step == "train":
            if self.val_size + self.test_size > 0:
                cutoff = -self.val_size - self.test_size
                temporal = temporal[:, :, :cutoff]

            temporal = self.padder_train(temporal)
            if temporal.shape[-1] < window_size:
                raise Exception(
                    "Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True"
                )
            windows = temporal.unfold(
                dimension=-1, size=window_size, step=self.step_size
            )

            # [B, C, Ws, L+H] 0, 1, 2, 3
            # -> [B * Ws, L+H, C] 0, 2, 3, 1
            windows_per_serie = windows.shape[2]
            windows = windows.permute(0, 2, 3, 1).contiguous()
            windows = windows.reshape(-1, window_size, len(temporal_cols))

            # Sample and Available conditions
            available_idx = temporal_cols.get_loc("available_mask")
            available_condition = windows[:, : self.input_size, available_idx]
            available_condition = torch.sum(available_condition, axis=1)
            final_condition = available_condition > 0
            if self.h > 0:
                sample_condition = windows[:, self.input_size :, available_idx]
                sample_condition = torch.sum(sample_condition, axis=1)
                final_condition = (sample_condition > 0) & (available_condition > 0)
            windows = windows[final_condition]

            # Parse Static data to match windows
            # [B, S_in] -> [B, Ws, S_in] -> [B*Ws, S_in]
            static = batch.get("static", None)
            static_cols = batch.get("static_cols", None)
            if static is not None:
                static = torch.repeat_interleave(
                    static, repeats=windows_per_serie, dim=0
                )
                static = static[final_condition]

            # Protection of empty windows
            if final_condition.sum() == 0:
                raise Exception("No windows available for training")

            # Sample windows
            n_windows = len(windows)
            if self.windows_batch_size is not None:
                w_idxs = np.random.choice(
                    n_windows,
                    size=self.windows_batch_size,
                    replace=(n_windows < self.windows_batch_size),
                )
                windows = windows[w_idxs]

                if static is not None:
                    static = static[w_idxs]

            # think about interaction available * sample mask
            # [B, C, Ws, L+H]
            windows_batch = dict(
                temporal=windows,
                temporal_cols=temporal_cols,
                static=static,
                static_cols=static_cols,
            )
            return windows_batch

        elif step in ["predict", "val"]:

            if step == "predict":
                initial_input = temporal.shape[-1] - self.test_size
                if (
                    initial_input <= self.input_size
                ):  # There is not enough data to predict first timestamp
                    padder_left = nn.ConstantPad1d(
                        padding=(self.input_size - initial_input, 0), value=0
                    )
                    temporal = padder_left(temporal)
                predict_step_size = self.predict_step_size
                cutoff = -self.input_size - self.test_size
                temporal = temporal[:, :, cutoff:]

            elif step == "val":
                predict_step_size = self.step_size
                cutoff = -self.input_size - self.val_size - self.test_size
                if self.test_size > 0:
                    temporal = batch["temporal"][:, :, cutoff : -self.test_size]
                else:
                    temporal = batch["temporal"][:, :, cutoff:]
                if temporal.shape[-1] < window_size:
                    initial_input = temporal.shape[-1] - self.val_size
                    padder_left = nn.ConstantPad1d(
                        padding=(self.input_size - initial_input, 0), value=0
                    )
                    temporal = padder_left(temporal) 

            if (
                (step == "predict")
                and (self.test_size == 0)
                and (len(self.futr_exog_list) == 0)
            ):
                #Willa update
                #shouldn't change anything since insample_y and outsample_y  
                # depend on self.input_size only

                #padder_right = nn.ConstantPad1d(padding=(0, self.h), value=0)
                padder_right = nn.ConstantPad1d(padding=(0, self.output_token_len), value=0) 
                temporal = padder_right(temporal)

            windows = temporal.unfold(
                dimension=-1, size=window_size, step=predict_step_size
            )

            # [batch, channels, windows, window_size] 0, 1, 2, 3
            # -> [batch * windows, window_size, channels] 0, 2, 3, 1
            windows_per_serie = windows.shape[2]
            windows = windows.permute(0, 2, 3, 1).contiguous()
            windows = windows.reshape(-1, window_size, len(temporal_cols))

            static = batch.get("static", None)
            static_cols = batch.get("static_cols", None)
            if static is not None:
                static = torch.repeat_interleave(
                    static, repeats=windows_per_serie, dim=0
                )

            # Sample windows for batched prediction
            if w_idxs is not None:
                windows = windows[w_idxs]
                if static is not None:
                    static = static[w_idxs]

            windows_batch = dict(
                temporal=windows,
                temporal_cols=temporal_cols,
                static=static,
                static_cols=static_cols,
            )
            return windows_batch
        else:
            raise ValueError(f"Unknown step {step}")

    def _normalization(self, windows, y_idx):
        # windows are already filtered by train/validation/test
        # from the `create_windows_method` nor leakage risk
        temporal = windows["temporal"]  # B, L+H, C
        temporal_cols = windows["temporal_cols"].copy()  # B, L+H, C

        # To avoid leakage uses only the lags
        # temporal_data_cols = temporal_cols.drop('available_mask').tolist()
        temporal_data_cols = self._get_temporal_exogenous_cols(
            temporal_cols=temporal_cols
        )
        temporal_idxs = get_indexer_raise_missing(temporal_cols, temporal_data_cols)
        temporal_idxs = np.append(y_idx, temporal_idxs)
        temporal_data = temporal[:, :, temporal_idxs]
        temporal_mask = temporal[:, :, temporal_cols.get_loc("available_mask")].clone()
        if self.h > 0:
            temporal_mask[:, -self.h :] = 0.0

        # Normalize. self.scaler stores the shift and scale for inverse transform
        temporal_mask = temporal_mask.unsqueeze(
            -1
        )  # Add channel dimension for scaler.transform.
        temporal_data = self.scaler.transform(x=temporal_data, mask=temporal_mask)

        # Replace values in windows dict
        temporal[:, :, temporal_idxs] = temporal_data
        windows["temporal"] = temporal

        return windows

    def _inv_normalization(self, y_hat, y_idx):
        # Receives window predictions [B, H, output]
        # Broadcasts outputs and inverts normalization

        # Add C dimension
        if y_hat.ndim == 2:
            remove_dimension = True
            y_hat = y_hat.unsqueeze(-1)
        else:
            remove_dimension = False

        y_scale = self.scaler.x_scale[:, :, [y_idx]]
        y_loc = self.scaler.x_shift[:, :, [y_idx]]

        y_scale = torch.repeat_interleave(y_scale, repeats=y_hat.shape[-1], dim=-1).to(
            y_hat.device
        )
        y_loc = torch.repeat_interleave(y_loc, repeats=y_hat.shape[-1], dim=-1).to(
            y_hat.device
        )

        y_hat = self.scaler.inverse_transform(z=y_hat, x_scale=y_scale, x_shift=y_loc)
        y_loc = y_loc.to(y_hat.device)
        y_scale = y_scale.to(y_hat.device)

        if remove_dimension:
            y_hat = y_hat.squeeze(-1)
            y_loc = y_loc.squeeze(-1)
            y_scale = y_scale.squeeze(-1)

        return y_hat, y_loc, y_scale

    def _parse_windows(self, batch, windows):
        # Filter insample lags from outsample horizon
        y_idx = batch["y_idx"]
        mask_idx = batch["temporal_cols"].get_loc("available_mask")

        insample_y = windows["temporal"][:, : self.input_size, y_idx]
        insample_mask = windows["temporal"][:, : self.input_size, mask_idx]

        # Declare additional information
        outsample_y = None
        outsample_mask = None
        hist_exog = None
        futr_exog = None
        stat_exog = None

        if self.h > 0:
            outsample_y = windows["temporal"][:, self.input_size :, y_idx]
            outsample_mask = windows["temporal"][:, self.input_size :, mask_idx]

        if len(self.hist_exog_list):
            hist_exog_idx = get_indexer_raise_missing(
                windows["temporal_cols"], self.hist_exog_list
            )
            hist_exog = windows["temporal"][:, : self.input_size, hist_exog_idx]

        if len(self.futr_exog_list):
            futr_exog_idx = get_indexer_raise_missing(
                windows["temporal_cols"], self.futr_exog_list
            )
            futr_exog = windows["temporal"][:, :, futr_exog_idx]

        if len(self.stat_exog_list):
            static_idx = get_indexer_raise_missing(
                windows["static_cols"], self.stat_exog_list
            )
            stat_exog = windows["static"][:, static_idx]

        # TODO: think a better way of removing insample_y features
        if self.exclude_insample_y:
            insample_y = insample_y * 0

        return (
            insample_y,
            insample_mask,
            outsample_y,
            outsample_mask,
            hist_exog,
            futr_exog,
            stat_exog,
        )

    def training_step(self, batch, batch_idx):
        # Create and normalize windows [Ws, L+H, C]
        window_size = self.input_size + self.output_token_len
        windows = self._create_windows(batch, window_size=window_size, step="train")
        y_idx = batch["y_idx"]
        #original_outsample_y = torch.clone(windows["temporal"][:, -self.h :, y_idx])
        original_outsample_y = torch.clone(windows["temporal"][:, -self.output_token_len :, y_idx])
        windows = self._normalization(windows=windows, y_idx=y_idx)

        # Parse windows
        (
            insample_y,
            insample_mask,
            outsample_y,
            outsample_mask,
            hist_exog,
            futr_exog,
            stat_exog,
        ) = self._parse_windows(batch, windows)

        windows_batch = dict(
            insample_y=insample_y,  # [Ws, L]
            insample_mask=insample_mask,  # [Ws, L]
            futr_exog=futr_exog,  # [Ws, L + h, F]
            hist_exog=hist_exog,  # [Ws, L, X]
            stat_exog=stat_exog,
        )  # [Ws, S]

        output = self.model_output(windows_batch)
        # binning creates classes
        if self.tokenizer_type=='bins':
            #print('before', original_outsample_y)
            original_outsample_y = original_outsample_y.unsqueeze(1)
            original_outsample_y = self.tokenizer.output_transform(original_outsample_y)
            original_outsample_y = original_outsample_y.squeeze(1).squeeze(-1)
            #print('after', original_outsample_y)

        if self.loss.is_distribution_output:
            _, y_loc, y_scale = self._inv_normalization(
                y_hat=outsample_y, 
                #temporal_cols=batch["temporal_cols"], 
                y_idx=y_idx
            )
            outsample_y = original_outsample_y
            distr_args = self.loss.scale_decouple(
                output=output, loc=y_loc, scale=y_scale
            )
            loss = self.loss(y=outsample_y, distr_args=distr_args, mask=outsample_mask)
        else:
            loss = self.loss(y=outsample_y, y_hat=output, mask=outsample_mask)

        if torch.isnan(loss):
            print("Model Parameters", self.hparams)
            print("insample_y", torch.isnan(insample_y).sum())
            print("outsample_y", torch.isnan(outsample_y).sum())
            print("output", torch.isnan(output).sum())
            raise Exception("Loss is NaN, training stopped.")

        self.log(
            "train_loss",
            loss.item(),
            batch_size=outsample_y.size(0),
            prog_bar=True,
            on_epoch=True,
        )
        self.train_trajectories.append((self.global_step, loss.item()))
        return loss

    def _compute_valid_loss(
        self, outsample_y, output, outsample_mask, temporal_cols, y_idx
    ):
        if self.loss.is_distribution_output:
            _, y_loc, y_scale = self._inv_normalization(
                y_hat=outsample_y, 
                #temporal_cols=temporal_cols,
                y_idx=y_idx
            )
            distr_args = self.loss.scale_decouple(
                output=output, loc=y_loc, scale=y_scale
            )
            _, sample_mean, quants = self.loss.sample(distr_args=distr_args)

            if str(type(self.valid_loss)) in [
                "<class 'neuralforecast.losses.pytorch.sCRPS'>",
                "<class 'neuralforecast.losses.pytorch.MQLoss'>",
            ]:
                output = quants
            elif str(type(self.valid_loss)) in [
                "<class 'neuralforecast.losses.pytorch.relMSE'>"
            ]:
                output = torch.unsqueeze(sample_mean, dim=-1)  # [N,H,1] -> [N,H]

        # Validation Loss evaluation
        if self.valid_loss.is_distribution_output:
            valid_loss = self.valid_loss(
                y=outsample_y, distr_args=distr_args, mask=outsample_mask
            )
        else:
            output, _, _ = self._inv_normalization(
                y_hat=output, 
                #temporal_cols=temporal_cols,
                y_idx=y_idx
            )
            valid_loss = self.valid_loss(
                y=outsample_y, y_hat=output, mask=outsample_mask
            )
        return valid_loss


    def validation_step(self, batch, batch_idx):
        if self.val_size == 0:
            return np.nan

        # using window_size = self.input_size + self.token_len is given error when identifying windows with w_idxs
        window_size = self.input_size + self.h

        # TODO: Hack to compute number of windows
        windows = self._create_windows(batch, window_size=window_size, step="val")
        n_windows = len(windows["temporal"])
        y_idx = batch["y_idx"]
        mask_idx = batch["temporal_cols"].get_loc("available_mask")
        
        # Number of windows in batch
        windows_batch_size = self.inference_windows_batch_size

        #Calculate how many times each window should be repeated
        n_repeats = int(torch.ceil(torch.tensor([self.h/self.output_token_len])))
        # Repeat each index in the range of n_windows, n_repeats times
        n_batches = int(np.ceil(n_windows / windows_batch_size))
        repeated_idxs = torch.arange(n_batches).repeat_interleave(n_repeats)
        
        # if n_windows < windows_batch_size results will equal n_windows
        # if n_batches==1 and n_windows<windows_batch_size, previous_preds.shape[0]==n_windows==remainder_windows_count
        remainder_windows_count = n_windows%windows_batch_size

        valid_losses = []
        batch_sizes = []

        previous_preds = torch.zeros(windows_batch_size, self.output_token_len*n_repeats, 
                                     device=windows["temporal"].device)
        previous_params = torch.zeros(windows_batch_size, self.output_token_len*n_repeats, self.c_out, 
                                      device=windows["temporal"].device)

        for fi, i in enumerate(repeated_idxs):
            # Create and normalize windows [Ws, L+H, C]
            w_idxs = np.arange(
                i * windows_batch_size, min((i + 1) * windows_batch_size, n_windows)
            )
            windows = self._create_windows(batch, window_size=window_size, step="val", w_idxs=w_idxs)
            
            (
                insample_y,
                insample_mask,
                _,
                _,
                hist_exog,
                futr_exog,
                stat_exog,
            ) = self._parse_windows(batch, windows)

            # Concatenate along dimension 1
            pos = fi % n_repeats
            if pos != 0:
                seq_preds = previous_preds[:, : self.output_token_len*pos].clone()
                y_hat, _, _ = self._inv_normalization(
                        y_hat=seq_preds,
                        y_idx=y_idx,
                        )
  
                horizon_filler = torch.zeros(insample_y.shape[0], self.h).to(windows['temporal'].device)
                insample_y = torch.cat((insample_y, 
                                        y_hat, 
                                        horizon_filler), 
                                       dim=1)
                
                extend_mask = torch.ones(insample_y.shape[0],
                                    self.output_token_len*pos
                                    ).to(windows['temporal'].device)
                insample_mask = torch.cat((insample_mask, 
                                           extend_mask,
                                           horizon_filler),
                                          dim=1)
                
                 # Shift insample_y by patches to include new appended predictions
                insample_y = insample_y[:, self.output_token_len*pos :]
                insample_mask = insample_mask[:, self.output_token_len*pos :]
                
                wcat = torch.zeros(insample_y.shape[0],
                                   insample_y.shape[1], 
                                   2).to(windows['temporal'].device)
                wcat[:, :, y_idx] = insample_y
                wcat[:, :, mask_idx] = insample_mask
                windows["temporal"] = wcat

            else:
                if (i == torch.max(repeated_idxs)) & (remainder_windows_count!=0):
                    previous_preds = torch.zeros(remainder_windows_count, self.output_token_len*n_repeats, 
                                                 device=windows["temporal"].device)
                    previous_params = torch.zeros(remainder_windows_count, self.output_token_len*n_repeats, self.c_out,
                                     device=windows["temporal"].device)
                else:
                    previous_preds = torch.zeros(windows_batch_size, self.output_token_len*n_repeats, 
                                     device=windows["temporal"].device)
                    previous_params = torch.zeros(windows_batch_size, self.output_token_len*n_repeats, self.c_out,
                                     device=windows["temporal"].device)
            
            windows = self._normalization(windows=windows, y_idx=y_idx)

            (
                insample_y,
                insample_mask,
                _,
                _,
                hist_exog,
                futr_exog,
                stat_exog,
            ) = self._parse_windows(batch, windows)

            windows_batch = dict(
                insample_y=insample_y,  # [Ws, L]
                insample_mask=insample_mask,  # [Ws, L]
                futr_exog=futr_exog,  # [Ws, L + h, F]
                hist_exog=hist_exog,  # [Ws, L, X]
                stat_exog=stat_exog,
            )  # [Ws, S]

            output = self.model_output(windows_batch)
            
            y_hat = self._get_predictions(
                        batch=batch,
                        insample_y=insample_y,
                        output_batch=output,
                        y_idx=batch["y_idx"],
                        )
            #print(y_hat[0])
            if self.loss.is_distribution_output:
                y_hat = y_hat[:, :, 0]
                output_stack = torch.stack(output, dim=-1)
                previous_params[:, self.output_token_len*pos : self.output_token_len*pos+self.output_token_len, :] = output_stack
            previous_preds[:, self.output_token_len*pos : self.output_token_len*pos+self.output_token_len] = y_hat

            if (fi+1) % n_repeats == 0:
                if self.loss.is_distribution_output:
                    output_horizon = previous_params[:, : self.h, :]
                    output_horizon = torch.unbind(output_horizon, dim=-1)
                else:
                    output_horizon = previous_preds[:, : self.h]
                windows_h = self._create_windows(batch, window_size=window_size, 
                                                 step="val", w_idxs=w_idxs)
                original_outsample_y = torch.clone(windows_h["temporal"][:, -self.h :, y_idx])
                # binning creates classes
                if self.tokenizer_type=='bins':
                    original_outsample_y = original_outsample_y.unsqueeze(1)
                    original_outsample_y = self.tokenizer.output_transform(original_outsample_y)
                    original_outsample_y = original_outsample_y.squeeze(1).squeeze(-1)

                (
                insample_y,
                insample_mask,
                _,
                outsample_mask,
                hist_exog,
                futr_exog,
                stat_exog,
                ) = self._parse_windows(batch, windows_h)
                
                valid_loss_batch = self._compute_valid_loss(
                    outsample_y=original_outsample_y,
                    output=output_horizon,
                    outsample_mask=outsample_mask,
                    temporal_cols=batch["temporal_cols"],
                    y_idx=batch["y_idx"],
                )
                valid_losses.append(valid_loss_batch)
                batch_sizes.append(len(output))
            else:
                continue

        valid_loss = torch.stack(valid_losses)
        batch_sizes = torch.tensor(batch_sizes, device=valid_loss.device)
        batch_size = torch.sum(batch_sizes)
        valid_loss = torch.sum(valid_loss * batch_sizes) / batch_size

        if torch.isnan(valid_loss):
            raise Exception("Loss is NaN, training stopped.")

        self.log(
            "valid_loss",
            valid_loss.item(),
            batch_size=batch_size,
            prog_bar=True,
            on_epoch=True,
        )
        self.validation_step_outputs.append(valid_loss)
        return valid_loss


    def predict_step(self, batch, batch_idx):

        window_size = self.input_size + self.h

       # TODO: Hack to compute number of windows
        windows = self._create_windows(batch, window_size=window_size, step="predict")
        n_windows = len(windows["temporal"])
        y_idx = batch["y_idx"]
        mask_idx = batch["temporal_cols"].get_loc("available_mask")

        # Number of windows in batch
        windows_batch_size = self.inference_windows_batch_size

        #Calculate how many times each window should be repeated
        n_repeats = int(torch.ceil(torch.tensor([self.h/self.output_token_len])))
        # Repeat each index in the range of n_windows, n_repeats times
        n_batches = int(np.ceil(n_windows / windows_batch_size))
        repeated_idxs = torch.arange(n_batches).repeat_interleave(n_repeats)
        
        # if n_windows < windows_batch_size results will equal n_windows
        remainder_windows_count = n_windows%windows_batch_size
        
        previous_preds = torch.zeros(windows_batch_size, 
                                     self.output_token_len*n_repeats, 
                                     device=windows["temporal"].device
                                    )
        
        previous_params = torch.zeros(windows_batch_size, self.output_token_len*n_repeats, self.c_out, 
                                      device=windows["temporal"].device)

        y_hats = []
        for fi, i in enumerate(repeated_idxs):
            # Create and normalize windows [Ws, L+H, C]
            w_idxs = np.arange(
                i * windows_batch_size, min((i + 1) * windows_batch_size, n_windows)
            )
            windows = self._create_windows(batch, window_size=window_size, step="predict", w_idxs=w_idxs)

            # parse_windows removes horizon from insample_y
            (
                insample_y,
                insample_mask,
                _,
                _,
                hist_exog,
                futr_exog,
                stat_exog,
            ) = self._parse_windows(batch, windows) 

            # Concatenate along dimension 1
            pos = fi % n_repeats
            if pos != 0:
                seq_preds = previous_preds[:, : self.output_token_len*pos].clone()
                y_hat, _, _ = self._inv_normalization(
                    y_hat=seq_preds,
                    y_idx=y_idx,
                    )

                horizon_filler = torch.zeros(insample_y.shape[0], self.h).to(windows['temporal'].device)
                insample_y = torch.cat((insample_y, 
                                        y_hat, 
                                        horizon_filler), 
                                       dim=1)
                
                extend_mask = torch.ones(insample_y.shape[0],
                                    self.output_token_len*pos
                                    ).to(windows['temporal'].device)
                insample_mask = torch.cat((insample_mask, 
                                           extend_mask,
                                           horizon_filler),
                                          dim=1)
                
                 # Shift insample_y by patches to include new appended predictions
                insample_y = insample_y[:, self.output_token_len*pos :]
                insample_mask = insample_mask[:, self.output_token_len*pos :]
                
                wcat = torch.zeros(insample_y.shape[0],
                                   insample_y.shape[1], 
                                   2).to(windows['temporal'].device)
                wcat[:, :, y_idx] = insample_y
                wcat[:, :, mask_idx] = insample_mask
                windows["temporal"] = wcat
                
            else:
                if (i == torch.max(repeated_idxs)) & (remainder_windows_count!=0):
                    previous_preds = torch.zeros(remainder_windows_count, self.output_token_len*n_repeats, 
                                                 device=windows["temporal"].device
                                                )
                    previous_params = torch.zeros(remainder_windows_count, self.output_token_len*n_repeats, self.c_out, 
                                      device=windows["temporal"].device)
                else:
                    previous_preds = torch.zeros(windows_batch_size, self.output_token_len*n_repeats, 
                                                 device=windows["temporal"].device
                                                )
                    previous_params = torch.zeros(windows_batch_size, self.output_token_len*n_repeats, self.c_out, 
                                      device=windows["temporal"].device)

            windows = self._normalization(windows=windows, y_idx=y_idx)

            (
                insample_y,
                insample_mask,
                _,
                _,
                hist_exog,
                futr_exog,
                stat_exog,
            ) = self._parse_windows(batch, windows)

            windows_batch = dict(
                insample_y=insample_y,  # [Ws, L]
                insample_mask=insample_mask,  # [Ws, L]
                futr_exog=futr_exog,  # [Ws, L + h, F]
                hist_exog=hist_exog,  # [Ws, L, X]
                stat_exog=stat_exog,
            )  # [Ws, S]

            output = self.model_output(windows_batch)
            
            y_hat = self._get_predictions(
                        batch=batch,
                        insample_y=insample_y,
                        output_batch=output,
                        y_idx=batch["y_idx"],
                        )
            if self.loss.is_distribution_output:
                y_hat = y_hat[:, :, 0]
                output_stack = torch.stack(output, dim=-1)
                previous_params[:, self.output_token_len*pos : self.output_token_len*pos+self.output_token_len, :] = output_stack
            previous_preds[:, self.output_token_len*pos : self.output_token_len*pos+self.output_token_len] = y_hat

            if (fi+1) % n_repeats == 0:
                if self.loss.is_distribution_output:
                    output_horizon = previous_params[:, : self.h, :]
                    output_horizon = torch.unbind(output_horizon, dim=-1)
                else:
                    output_horizon = previous_preds[:, : self.h]

                y_hats.append(self._get_predictions(
                    batch=batch,
                    insample_y=insample_y,
                    output_batch=output_horizon,
                    y_idx=batch["y_idx"],
                    )
                )
            else:
                continue

        y_hat = torch.cat(y_hats, dim=0)
        if self.tokenizer_type=='bins':
            print('before_unbin', y_hat)
            y_hat = self.tokenizer.unbin(y_hat)
            print('final', y_hat)

        return y_hat


    def _get_predictions(self, batch, insample_y, output_batch, y_idx):
        # Inverse normalization and sampling
        if self.loss.is_distribution_output:
            _, y_loc, y_scale = self._inv_normalization(
                y_hat=torch.empty(
                    size=(insample_y.shape[0], self.h),
                    dtype=output_batch[0].dtype,
                    device=output_batch[0].device,
                ),
               # temporal_cols=batch["temporal_cols"],
                y_idx=y_idx,
            )
            distr_args = self.loss.scale_decouple(
                output=output_batch, loc=y_loc, scale=y_scale
            )
            _, sample_mean, quants = self.loss.sample(distr_args=distr_args)
            y_hat = torch.concat((sample_mean, quants), axis=2)

            if self.loss.return_params:
                distr_args = torch.stack(distr_args, dim=-1)
                distr_args = torch.reshape(
                    distr_args, (len(windows["temporal"]), self.h, -1)
                )
                y_hat = torch.concat((y_hat, distr_args), axis=2)
        else:
            y_hat, _, _ = self._inv_normalization(
                y_hat=output_batch,
               # temporal_cols=batch["temporal_cols"],
                y_idx=y_idx,
            )
        return y_hat

    def fit(
        self,
        dataset,
        val_size=0,
        test_size=0,
        random_seed=None,
        distributed_config=None,
    ):
        """Fit.

        The `fit` method, optimizes the neural network's weights using the
        initialization parameters (`learning_rate`, `windows_batch_size`, ...)
        and the `loss` function as defined during the initialization.
        Within `fit` we use a PyTorch Lightning `Trainer` that
        inherits the initialization's `self.trainer_kwargs`, to customize
        its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).

        The method is designed to be compatible with SKLearn-like classes
        and in particular to be compatible with the StatsForecast library.

        By default the `model` is not saving training checkpoints to protect
        disk memory, to get them change `enable_checkpointing=True` in `__init__`.

        **Parameters:**<br>
        `dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>
        `val_size`: int, validation size for temporal cross-validation.<br>
        `random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>
        `test_size`: int, test size for temporal cross-validation.<br>
        """
        return self._fit(
            dataset=dataset,
            batch_size=self.batch_size,
            valid_batch_size=self.valid_batch_size,
            val_size=val_size,
            test_size=test_size,
            random_seed=random_seed,
            distributed_config=distributed_config,
        )

    def predict(
        self,
        dataset,
        test_size=None,
        step_size=1,
        random_seed=None,
        **data_module_kwargs,
    ):
        """Predict.

        Neural network prediction with PL's `Trainer` execution of `predict_step`.

        **Parameters:**<br>
        `dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>
        `test_size`: int=None, test size for temporal cross-validation.<br>
        `step_size`: int=1, Step size between each window.<br>
        `random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>
        `**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).
        """
        self._check_exog(dataset)
        self._restart_seed(random_seed)
        data_module_kwargs = self._set_quantile_for_iqloss(**data_module_kwargs)

        self.predict_step_size = step_size
        self.decompose_forecast = False
        datamodule = TimeSeriesDataModule(
            dataset=dataset,
            valid_batch_size=self.valid_batch_size,
            **data_module_kwargs,
        )

        # Protect when case of multiple gpu. PL does not support return preds with multiple gpu.
        pred_trainer_kwargs = self.trainer_kwargs.copy()
        if (pred_trainer_kwargs.get("accelerator", None) == "gpu") and (
            torch.cuda.device_count() > 1
        ):
            pred_trainer_kwargs["devices"] = [0]

        trainer = pl.Trainer(**pred_trainer_kwargs)
        fcsts = trainer.predict(self, datamodule=datamodule)
        fcsts = torch.vstack(fcsts).numpy().flatten()
        fcsts = fcsts.reshape(-1, len(self.loss.output_names))
        return fcsts
    
    def model_output(self, windows_batch):
        # Move from model code
        insample_y = windows_batch["insample_y"]
        x = insample_y.unsqueeze(-1)  # [Ws,L,1]
        #print('insample_y', x[0])
        x = x.permute(0, 2, 1)  # x: [Batch, 1, input_size]
        if self.revin:
            x = x.permute(0, 2, 1)
            x = self.revin_layer(x, "norm")
            x = x.permute(0, 2, 1)
        # tokenize input
       # print('revin', x[0])
        z = self.tokenizer.output_transform(x) 
        #print('tokenize', z[0])

        # Model Predictions
        output = self(z)

        if self.revin:
            output = output.permute(0, 2, 1)
            output = self.revin_layer(output, "denorm")
            output = output.permute(0, 2, 1)

        output = output.reshape(output.shape[0], self.h, self.c_out)  # x: [Batch, h, c_out]
        output = self.loss.domain_map(output)
        
        return output

    def decompose(self, dataset, step_size=1, random_seed=None, **data_module_kwargs):
        """Decompose Predictions.

        Decompose the predictions through the network's layers.
        Available methods are `ESRNN`, `NHITS`, `NBEATS`, and `NBEATSx`.

        **Parameters:**<br>
        `dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation here](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>
        `step_size`: int=1, step size between each window of temporal data.<br>
        `**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).
        """
        # Restart random seed
        if random_seed is None:
            random_seed = self.random_seed
        torch.manual_seed(random_seed)
        data_module_kwargs = self._set_quantile_for_iqloss(**data_module_kwargs)

        self.predict_step_size = step_size
        self.decompose_forecast = True
        datamodule = TimeSeriesDataModule(
            dataset=dataset,
            valid_batch_size=self.valid_batch_size,
            **data_module_kwargs,
        )
        trainer = pl.Trainer(**self.trainer_kwargs)
        fcsts = trainer.predict(self, datamodule=datamodule)
        self.decompose_forecast = False  # Default decomposition back to false
        return torch.vstack(fcsts).numpy()
